{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc712d0",
   "metadata": {},
   "source": [
    "Join operation có 3 tiêu chí:\n",
    "\n",
    "* Broadcast joins for unbalanced datasets\n",
    "* Sort-merge joins for large-scale data\n",
    "* Multiple joins optimization\n",
    "\n",
    "\n",
    "Tất cả các phương thức join trên đều được tự động nhận diện tùy vào 2 bảng cần join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484ff6b",
   "metadata": {},
   "source": [
    "Load data vào và build bảng chứa company_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JSONL_Loader\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01180136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chưa cần chạy vội\n",
    "hdfs_path = \"hdfs://<your_hdfs_namenode>:<port>/path/to/your/file.jsonl\"\n",
    "\n",
    "df_raw = spark.read.json(hdfs_path)\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2757fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử nghiệm\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_flat = df_raw.select(\n",
    "    col(\"job_title\"),\n",
    "    col(\"company_name\").alias(\"main_company_name\"), # Đổi tên để tránh trùng lặp\n",
    "    col(\"salary\"),\n",
    "    # Trích xuất các trường con từ 'company_detail'\n",
    "    col(\"company_detail.company_name\").alias(\"detail_company_name\"),\n",
    "    col(\"company_detail.declaration\"),\n",
    "    col(\"company_detail.`Company type`\").alias(\"company_type\"), # Dùng dấu `` cho tên cột có khoảng trắng\n",
    "    col(\"company_detail.`Company industry`\").alias(\"company_industry\"),\n",
    "    col(\"company_detail.`Company size`\").alias(\"company_size\"),\n",
    "    col(\"company_detail.Country\"),\n",
    "    col(\"company_detail.`Working days`\").alias(\"working_days\"),\n",
    "    col(\"company_detail.`Overtime policy`\").alias(\"overtime_policy\")\n",
    "    \n",
    ")\n",
    "\n",
    "df_flat.printSchema()\n",
    "df_flat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_detail = df_raw.select(\n",
    "    \n",
    "    \n",
    "    # Trích xuất các trường con từ 'company_detail'\n",
    "    col(\"company_detail.company_name\").alias(\"company_key\"),\n",
    "    col(\"company_detail.declaration\"),\n",
    "    col(\"company_detail.`Company type`\").alias(\"company_type\"), # Dùng dấu `` cho tên cột có khoảng trắng\n",
    "    col(\"company_detail.`Company industry`\").alias(\"company_industry\"),\n",
    "    col(\"company_detail.`Company size`\").alias(\"company_size\"),\n",
    "    col(\"company_detail.Country\"),\n",
    "    col(\"company_detail.`Working days`\").alias(\"working_days\"),\n",
    "    col(\"company_detail.`Overtime policy`\").alias(\"overtime_policy\")\n",
    "    \n",
    ").distinct()\n",
    "\n",
    "# df chính để join broadcast\n",
    "df_job = df_raw.select(\n",
    "    col(\"*\"),\n",
    "    col(\"company_name\").alias(\"company_key_for_join\")\n",
    ").drop(\"company_detail\") # Xóa cột lồng nhau sau khi đã trích xuất Khóa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d07469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0a582c",
   "metadata": {},
   "source": [
    "**Xử lý _broadcast join for unbalanced dataset_** bằng cách sử dụng trường thông tin company_detail chỉ có ở IT_viec rồi join với các bảng chung khác (bởi vì 1 công ty có thể đăng tuyển ở nhiều web).\n",
    "\n",
    "Cụ thể hơn thì load bảng company_detail này vào bộ nhớ cache của tất cả các worker để làm việc nhanh chóng hơn.\n",
    "\n",
    "Cách thức hoạt động: Apache Spark sẽ gửi toàn bộ bảng nhỏ hơn đến bộ nhớ đệm (cache) của mỗi node trong cluster. Việc join sau đó diễn ra cục bộ trên mỗi node mà không cần trao đổi dữ liệu qua mạng (shuffle), giúp giảm đáng kể độ trễ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e268a",
   "metadata": {},
   "source": [
    "**Broadcast tự động**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e9af8",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# ngưỡng 20MB\n",
    "\n",
    "# cấu hình từ đầu\n",
    "spark_auto = SparkSession.builder \\\n",
    "    .appName(\"AutoBroadcastJoin\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"20971520\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "# cấu hình trong lúc chạy\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 15728640)  # 15MB\n",
    "\n",
    "# Spark tự động kiểm tra kích thước df_nho và áp dụng Broadcast Join\n",
    "df_ket_qua_auto = df_job.join(\n",
    "    df_company_detail,\n",
    "    df_job[\"ma_ky_nang\"] == df_company_detail[\"ma_ky_nang\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Để xem kế hoạch thực thi (Execution Plan) và xác nhận Broadcast Join được áp dụng:\n",
    "print(\"--- Execution Plan (Auto Broadcast) ---\")\n",
    "df_ket_qua_auto.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a7aa4",
   "metadata": {},
   "source": [
    "**Thủ công**\n",
    "\n",
    "Với dữ liệu của mình thì company_detail chỉ khoảng 300-400KB, còn df trong bộ nhớ ram thì khoảng 1.1 MB - 3.8 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23489454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "df_ket_qua_manual = df_job.join(\n",
    "    # Sử dụng hàm broadcast() trên DataFrame nhỏ hơn\n",
    "    broadcast(df_company_detail), \n",
    "    df_job[\"ma_ky_nang\"] == df_company_detail[\"ma_ky_nang\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Xem kết quả\n",
    "df_ket_qua_manual.show()\n",
    "\n",
    "# Xem kế hoạch thực thi để xác nhận (chắc chắn sẽ là BroadcastHashJoin)\n",
    "print(\"--- Execution Plan (Manual Broadcast) ---\")\n",
    "df_ket_qua_manual.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2626fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6df01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fcafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a0bdb0",
   "metadata": {},
   "source": [
    "**Xử lý _Sort-merge joins for large-scale data_** (nghĩa là xử lý 2 bảng lớn)\n",
    "\n",
    "Cơ chế: shuffle - sort - merge. Shuffle trên toàn cụm để các key join phù hợp nằm về cùng worker/partition. Sort để sắp xếp các mẫu dữ liệu trong 1 partition 1 cách có trật tự. Merge giống như trong sắp xếp merge-sort, duyệt qua từng mẫu của 2 bên để khớp key join với nhau.\n",
    "\n",
    "Triển khai:\n",
    "\n",
    "Đây là tự động nếu gọi join 2 bảng lớn\n",
    "\n",
    "Vì chưa biết cần join những bảng lớn nào nên cứ partition làm sao cho tối ưu bước lưu trữ. Đến bước này thì shuffle lại. Bước shuffle là bước có cost lớn nhất nên cần tối ưu, nếu bắt buộc (thường dùng) thì partition trước. Nên sử dụng 2 bảng có tính đồng nhất cao để join để bớt bước shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e110a",
   "metadata": {},
   "source": [
    "Tải thêm dataset từ huggingface để join\n",
    "* IT resume https://huggingface.co/datasets/datasetmaster/resumes\n",
    "* IT Job Roles Skills Dataset - kaggle/huggingface https://huggingface.co/datasets/NxtGenIntern/IT_Job_Roles_Skills_Certifications_Dataset\n",
    "\n",
    "Triển khai:\n",
    "* Với IT resume: explode cột skill của 2 bảng job và resume rồi join merge để kiểm tra sự chồng chéo skill giữa 2 bảng, nó sẽ tạo ra một bảng trung gian cực lớn được join theo từng kĩ năng, sau đó có thể ứng dụng tiếp. \n",
    "  * Ý nghĩa: \n",
    "    * Nhu cầu tương đối: Kỹ năng nào được yêu cầu nhiều (Job_ID lặp lại nhiều) và có nhiều ứng viên (Resume_ID lặp lại nhiều) cùng một lúc. \n",
    "    * Mức độ cạnh tranh: Bằng cách GROUP BY Skill_Name và COUNT (Job_ID) / COUNT (Resume_ID), bạn có thể đo lường mức độ cạnh tranh thực tế của một kỹ năng trên thị trường.\n",
    "\n",
    "Ý tưởng:\n",
    "* IT job - IT skill theo các key trung gian: \n",
    "  * IT role(vị trí công việc): chi tiết hơn về công việc\n",
    "  * skill name: đề xuất các certificate với mỗi công việc, skill\n",
    "* IT resume - IT skill:\n",
    "  * skill/role: đề xuất certificate cần thêm với skill, role ứng tuyển hiện tại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d5fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6a7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1a646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ba55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bdbb199",
   "metadata": {},
   "source": [
    "**Xử lý _Multiple Joins Optimization_** \n",
    "\n",
    "Mục tiêu là giảm số lần shuffle và điều chỉnh thứ tự join để tối ưu\n",
    "\n",
    "Tối ưu thứ tự join (Thực hiện phép join giúp giảm kích thước data nhanh nhất trước):\n",
    "* Join các bảng nhỏ nhất trước: Join bảng thực tế (fact table) với các bảng chiều (dimension tables) nhỏ trước, đặc biệt là các bảng có thể được broadcast. Điều này giúp giảm kích thước của tập kết quả trung gian trước khi join với các bảng lớn hơn.\n",
    "\n",
    "* Sử dụng CBO (Cost-Based Optimizer): Spark có một bộ tối ưu hóa truy vấn (Query Optimizer) mạnh mẽ. Nó cố gắng tự động tìm ra thứ tự join tốt nhất dựa trên các số liệu thống kê (cardinality, kích thước bảng, v.v.). Trong đây thì cần thu thập thông kê các bảng lớn trước. ANALYZE TABLE ten_bang COMPUTE STATISTICS FOR ALL COLUMNS;\n",
    "\n",
    "Giảm shuffle:\n",
    "* Thường xuyên broadcast các bảng nhỏ\n",
    "* Dùng bucket join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6d4ff",
   "metadata": {},
   "source": [
    "Triển khai với 3 bảng trên:\n",
    "* Thứ tự join sẽ là job-skill -> resume-skill ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a70b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956024a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313f740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968bf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e62ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e8f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c632e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
