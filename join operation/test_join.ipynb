{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc712d0",
   "metadata": {},
   "source": [
    "Join operation có 3 tiêu chí:\n",
    "\n",
    "* Broadcast joins for unbalanced datasets\n",
    "* Sort-merge joins for large-scale data\n",
    "* Multiple joins optimization\n",
    "\n",
    "\n",
    "Tất cả các phương thức join trên đều được tự động nhận diện tùy vào 2 bảng cần join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484ff6b",
   "metadata": {},
   "source": [
    "Load data vào và build bảng chứa company_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8569e16",
   "metadata": {},
   "source": [
    "TODO là phần cần chỉnh sửa\n",
    "\n",
    "CHƯA CHẠY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4128299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JSONL_Loader\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db05015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Khởi tạo Spark Session (Bắt buộc)\n",
    "# Thêm config dfs.client.use.datanode.hostname để fix lỗi kết nối DataNode\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Doc Data Tu HDFS\") \\\n",
    "    .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Đường dẫn HDFS (Sửa lại host/port cho đúng với setup của bạn)\n",
    "# Nếu chạy từ local máy tính kết nối vào Docker: dùng localhost hoặc host.docker.internal\n",
    "hdfs_path = \"hdfs://host.docker.internal:9000/path/to/file.jsonl\" \n",
    "# Hoặc nếu chạy production/internal network:\n",
    "# hdfs_path = \"hdfs://namenode:9000/path/to/file.jsonl\"\n",
    "\n",
    "# 3. Đọc file\n",
    "# Do Spark hoạt động theo cơ chế Lazy Evaluation, dòng này chỉ mới check metadata\n",
    "df_raw = spark.read.json(hdfs_path)\n",
    "\n",
    "# 4. In Schema (Dòng này mới thực sự kích hoạt việc kết nối tới NameNode/DataNode)\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01180136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chưa cần chạy vội\n",
    "hdfs_path = \"hdfs://<your_hdfs_namenode>:<port>/path/to/your/file.jsonl\"\n",
    "# hdfs_path = \"hdfs://host.docker.internal:9000/path/to/file.jsonl\"\n",
    "\n",
    "df_raw = spark.read.json(hdfs_path)\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c835b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2757fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử nghiệm\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_flat = df_raw.select(\n",
    "    col(\"job_title\"),\n",
    "    col(\"company_name\").alias(\"main_company_name\"), # Đổi tên để tránh trùng lặp\n",
    "    col(\"salary\"),\n",
    "    # Trích xuất các trường con từ 'company_detail'\n",
    "    col(\"company_detail.company_name\").alias(\"detail_company_name\"),\n",
    "    col(\"company_detail.declaration\"),\n",
    "    col(\"company_detail.`Company type`\").alias(\"company_type\"), # Dùng dấu `` cho tên cột có khoảng trắng\n",
    "    col(\"company_detail.`Company industry`\").alias(\"company_industry\"),\n",
    "    col(\"company_detail.`Company size`\").alias(\"company_size\"),\n",
    "    col(\"company_detail.Country\"),\n",
    "    col(\"company_detail.`Working days`\").alias(\"working_days\"),\n",
    "    col(\"company_detail.`Overtime policy`\").alias(\"overtime_policy\")\n",
    "    \n",
    ")\n",
    "\n",
    "df_flat.printSchema()\n",
    "df_flat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_detail = df_raw.select(\n",
    "    \n",
    "    \n",
    "    # Trích xuất các trường con từ 'company_detail'\n",
    "    col(\"company_detail.company_name\").alias(\"company_key\"),\n",
    "    col(\"company_detail.declaration\"),\n",
    "    col(\"company_detail.`Company type`\").alias(\"company_type\"), # Dùng dấu `` cho tên cột có khoảng trắng\n",
    "    col(\"company_detail.`Company industry`\").alias(\"company_industry\"),\n",
    "    col(\"company_detail.`Company size`\").alias(\"company_size\"),\n",
    "    col(\"company_detail.Country\"),\n",
    "    col(\"company_detail.`Working days`\").alias(\"working_days\"),\n",
    "    col(\"company_detail.`Overtime policy`\").alias(\"overtime_policy\")\n",
    "    \n",
    ").distinct()\n",
    "\n",
    "# df chính để join broadcast\n",
    "df_job = df_raw.select(\n",
    "    col(\"*\"),\n",
    "    col(\"company_name\").alias(\"company_key_for_join\")\n",
    ").drop(\"company_detail\") # Xóa cột lồng nhau sau khi đã trích xuất Khóa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44540a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d07469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0a582c",
   "metadata": {},
   "source": [
    "**Xử lý _broadcast join for unbalanced dataset_** bằng cách sử dụng trường thông tin company_detail chỉ có ở IT_viec rồi join với các bảng chung khác (bởi vì 1 công ty có thể đăng tuyển ở nhiều web).\n",
    "\n",
    "Cụ thể hơn thì load bảng company_detail này vào bộ nhớ cache của tất cả các worker để làm việc nhanh chóng hơn.\n",
    "\n",
    "Cách thức hoạt động: Apache Spark sẽ gửi toàn bộ bảng nhỏ hơn đến bộ nhớ đệm (cache) của mỗi node trong cluster. Việc join sau đó diễn ra cục bộ trên mỗi node mà không cần trao đổi dữ liệu qua mạng (shuffle), giúp giảm đáng kể độ trễ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e268a",
   "metadata": {},
   "source": [
    "**Broadcast tự động**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# ngưỡng 20MB\n",
    "\n",
    "# cấu hình từ đầu\n",
    "spark_auto = SparkSession.builder \\\n",
    "    .appName(\"AutoBroadcastJoin\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"20971520\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "# cấu hình trong lúc chạy\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 15728640)  # 15MB\n",
    "\n",
    "# Spark tự động kiểm tra kích thước df_nho và áp dụng Broadcast Join\n",
    "df_ket_qua_auto = df_job.join(\n",
    "    df_company_detail,\n",
    "    df_job[\"company_key_for_join\"] == df_company_detail[\"company_key\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Để xem kế hoạch thực thi (Execution Plan) và xác nhận Broadcast Join được áp dụng:\n",
    "print(\"--- Execution Plan (Auto Broadcast) ---\")\n",
    "df_ket_qua_auto.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a7aa4",
   "metadata": {},
   "source": [
    "**Thủ công**\n",
    "\n",
    "Với dữ liệu của mình thì company_detail chỉ khoảng 300-400KB, còn df trong bộ nhớ ram thì khoảng 1.1 MB - 3.8 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23489454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "df_ket_qua_manual = df_job.join(\n",
    "    # Sử dụng hàm broadcast() trên DataFrame nhỏ hơn\n",
    "    broadcast(df_company_detail), \n",
    "    df_job[\"company_key_for_join\"] == df_company_detail[\"company_key\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Xem kết quả\n",
    "df_ket_qua_manual.show()\n",
    "\n",
    "# Xem kế hoạch thực thi để xác nhận (chắc chắn sẽ là BroadcastHashJoin)\n",
    "print(\"--- Execution Plan (Manual Broadcast) ---\")\n",
    "df_ket_qua_manual.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2626fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6df01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fcafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a0bdb0",
   "metadata": {},
   "source": [
    "**Xử lý _Sort-merge joins for large-scale data_** (nghĩa là xử lý 2 bảng lớn)\n",
    "\n",
    "Cơ chế: shuffle - sort - merge. Shuffle trên toàn cụm để các key join phù hợp nằm về cùng worker/partition. Sort để sắp xếp các mẫu dữ liệu trong 1 partition 1 cách có trật tự. Merge giống như trong sắp xếp merge-sort, duyệt qua từng mẫu của 2 bên để khớp key join với nhau.\n",
    "\n",
    "Triển khai:\n",
    "\n",
    "Đây là tự động nếu gọi join 2 bảng lớn\n",
    "\n",
    "Vì chưa biết cần join những bảng lớn nào nên cứ partition làm sao cho tối ưu bước lưu trữ. Đến bước này thì shuffle lại. Bước shuffle là bước có cost lớn nhất nên cần tối ưu, nếu bắt buộc (thường dùng) thì partition trước. Nên sử dụng 2 bảng có tính đồng nhất cao để join để bớt bước shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e110a",
   "metadata": {},
   "source": [
    "Tải thêm dataset từ huggingface để join\n",
    "* IT resume https://huggingface.co/datasets/datasetmaster/resumes\n",
    "* IT Job Roles Skills Dataset - kaggle/huggingface https://huggingface.co/datasets/NxtGenIntern/IT_Job_Roles_Skills_Certifications_Dataset\n",
    "\n",
    "Triển khai:\n",
    "* Với IT resume: explode cột skill của 2 bảng job và resume rồi join merge để kiểm tra sự chồng chéo skill giữa 2 bảng, nó sẽ tạo ra một bảng trung gian cực lớn được join theo từng kĩ năng, sau đó có thể ứng dụng tiếp. \n",
    "  * Ý nghĩa: \n",
    "    * Nhu cầu tương đối: Kỹ năng nào được yêu cầu nhiều (Job_ID lặp lại nhiều) và có nhiều ứng viên (Resume_ID lặp lại nhiều) cùng một lúc. \n",
    "    * Mức độ cạnh tranh: Bằng cách GROUP BY Skill_Name và COUNT (Job_ID) / COUNT (Resume_ID), bạn có thể đo lường mức độ cạnh tranh thực tế của một kỹ năng trên thị trường.\n",
    "\n",
    "Ý tưởng:\n",
    "* IT job - IT skill theo các key trung gian: \n",
    "  * IT role(vị trí công việc): chi tiết hơn về công việc\n",
    "  * skill name: đề xuất các certificate với mỗi công việc, skill\n",
    "* IT resume - IT skill:\n",
    "  * skill/role: đề xuất certificate cần thêm với skill, role ứng tuyển hiện tại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716d5fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code language\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Job Title', 'Job Description', 'Skills', 'Certifications'],\n",
       "        num_rows: 207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "IT_skill = load_dataset(\"NxtGenIntern/IT_Job_Roles_Skills_Certifications_Dataset\")\n",
    "IT_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d10689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Certifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admin Big Data</td>\n",
       "      <td>Responsible for managing and overseeing big da...</td>\n",
       "      <td>Hadoop, Spark, MapReduce, Data Lakes, Data War...</td>\n",
       "      <td>Cloudera Certified Professional (CCP), Hortonw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ansible Operations Engineer</td>\n",
       "      <td>Focuses on automating IT processes using Ansib...</td>\n",
       "      <td>Ansible, Linux, Automation, Cloud Platforms, C...</td>\n",
       "      <td>Red Hat Certified Specialist in Ansible Automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artifactory Administrator</td>\n",
       "      <td>Manages the Artifactory repository for build a...</td>\n",
       "      <td>Artifactory, CI/CD, Jenkins, Docker, Maven, Gr...</td>\n",
       "      <td>JFrog Artifactory Certification, DevOps Instit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial intelligence / Machine Learning Eng...</td>\n",
       "      <td>No description available</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial Intelligence / Machine Learning Leader</td>\n",
       "      <td>Leads AI/ML projects and teams, defining strat...</td>\n",
       "      <td>AI Strategy, Machine Learning, Team Management...</td>\n",
       "      <td>AI-900: Microsoft Azure AI Fundamentals, Certi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Admin Big Data   \n",
       "1                        Ansible Operations Engineer   \n",
       "2                          Artifactory Administrator   \n",
       "3  Artificial intelligence / Machine Learning Eng...   \n",
       "4  Artificial Intelligence / Machine Learning Leader   \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  Responsible for managing and overseeing big da...   \n",
       "1  Focuses on automating IT processes using Ansib...   \n",
       "2  Manages the Artifactory repository for build a...   \n",
       "3                           No description available   \n",
       "4  Leads AI/ML projects and teams, defining strat...   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Hadoop, Spark, MapReduce, Data Lakes, Data War...   \n",
       "1  Ansible, Linux, Automation, Cloud Platforms, C...   \n",
       "2  Artifactory, CI/CD, Jenkins, Docker, Maven, Gr...   \n",
       "3                                                      \n",
       "4  AI Strategy, Machine Learning, Team Management...   \n",
       "\n",
       "                                      Certifications  \n",
       "0  Cloudera Certified Professional (CCP), Hortonw...  \n",
       "1  Red Hat Certified Specialist in Ansible Automa...  \n",
       "2  JFrog Artifactory Certification, DevOps Instit...  \n",
       "3                                                     \n",
       "4  AI-900: Microsoft Azure AI Fundamentals, Certi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "IT_skill_df = IT_skill[\"train\"]\n",
    "IT_skill_df = IT_skill_df.to_pandas()\n",
    "print(type(IT_skill_df))\n",
    "IT_skill_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd6a7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal_info</th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "      <th>skills</th>\n",
       "      <th>projects</th>\n",
       "      <th>certifications</th>\n",
       "      <th>achievements</th>\n",
       "      <th>workshops</th>\n",
       "      <th>publications</th>\n",
       "      <th>teaching_experience</th>\n",
       "      <th>internships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name': 'Unknown', 'email': 'Unknown', 'phone...</td>\n",
       "      <td>[{'company': 'Fresher', 'company_info': {'indu...</td>\n",
       "      <td>[{'degree': {'level': 'ME', 'field': 'Computer...</td>\n",
       "      <td>{'technical': {'programming_languages': [{'nam...</td>\n",
       "      <td>[{'name': 'Unknown', 'description': 'Unknown',...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name': 'Unknown', 'email': 'Unknown', 'phone...</td>\n",
       "      <td>[{'company': 'Delta Controls, Dubai FZCO', 'co...</td>\n",
       "      <td>[{'degree': {'level': 'B.E', 'field': 'Electro...</td>\n",
       "      <td>{'technical': {'project_management': [{'name':...</td>\n",
       "      <td>[{'name': 'FGP/WPMP', 'description': 'Led syst...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name': 'Not Provided', 'email': 'Not Provide...</td>\n",
       "      <td>[{'company': 'Parkar Consulting and Labs', 'co...</td>\n",
       "      <td>[{'degree': {'level': 'B.E.', 'field': 'Not Pr...</td>\n",
       "      <td>{'technical': {'programming_languages': [{'nam...</td>\n",
       "      <td>[{'name': 'FPGA Implementation', 'description'...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name': 'Unknown', 'email': 'Unknown', 'phone...</td>\n",
       "      <td>[{'company': 'Delta Controls, Dubai FZCO', 'co...</td>\n",
       "      <td>[{'degree': {'level': 'B.E', 'field': 'Electro...</td>\n",
       "      <td>{'technical': {'project_management': [{'name':...</td>\n",
       "      <td>[{'name': 'FGP/WPMP', 'description': 'Led syst...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name': '', 'email': '', 'phone': '', 'locati...</td>\n",
       "      <td>[{'company': 'Atos Syntel', 'company_info': {'...</td>\n",
       "      <td>[{'degree': {'level': 'Bachelor of Engineering...</td>\n",
       "      <td>{'technical': {'programming_languages': [{'nam...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{\"name\": \"ESD Program\", \"issuer\": \"Zensar Tech...</td>\n",
       "      <td>[Treasurer in IEEE student branch at JSCOE, Pu...</td>\n",
       "      <td>[{'name': 'Medical IoT', 'issuer': 'IEEE Stand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       personal_info  \\\n",
       "0  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
       "1  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
       "2  {'name': 'Not Provided', 'email': 'Not Provide...   \n",
       "3  {'name': 'Unknown', 'email': 'Unknown', 'phone...   \n",
       "4  {'name': '', 'email': '', 'phone': '', 'locati...   \n",
       "\n",
       "                                          experience  \\\n",
       "0  [{'company': 'Fresher', 'company_info': {'indu...   \n",
       "1  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
       "2  [{'company': 'Parkar Consulting and Labs', 'co...   \n",
       "3  [{'company': 'Delta Controls, Dubai FZCO', 'co...   \n",
       "4  [{'company': 'Atos Syntel', 'company_info': {'...   \n",
       "\n",
       "                                           education  \\\n",
       "0  [{'degree': {'level': 'ME', 'field': 'Computer...   \n",
       "1  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
       "2  [{'degree': {'level': 'B.E.', 'field': 'Not Pr...   \n",
       "3  [{'degree': {'level': 'B.E', 'field': 'Electro...   \n",
       "4  [{'degree': {'level': 'Bachelor of Engineering...   \n",
       "\n",
       "                                              skills  \\\n",
       "0  {'technical': {'programming_languages': [{'nam...   \n",
       "1  {'technical': {'project_management': [{'name':...   \n",
       "2  {'technical': {'programming_languages': [{'nam...   \n",
       "3  {'technical': {'project_management': [{'name':...   \n",
       "4  {'technical': {'programming_languages': [{'nam...   \n",
       "\n",
       "                                            projects  \\\n",
       "0  [{'name': 'Unknown', 'description': 'Unknown',...   \n",
       "1  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
       "2  [{'name': 'FPGA Implementation', 'description'...   \n",
       "3  [{'name': 'FGP/WPMP', 'description': 'Led syst...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      certifications  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  {\"name\": \"ESD Program\", \"issuer\": \"Zensar Tech...   \n",
       "\n",
       "                                        achievements  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [Treasurer in IEEE student branch at JSCOE, Pu...   \n",
       "\n",
       "                                           workshops publications  \\\n",
       "0                                                NaN          NaN   \n",
       "1                                                NaN          NaN   \n",
       "2                                                NaN          NaN   \n",
       "3                                                NaN          NaN   \n",
       "4  [{'name': 'Medical IoT', 'issuer': 'IEEE Stand...          NaN   \n",
       "\n",
       "  teaching_experience internships  \n",
       "0                 NaN         NaN  \n",
       "1                 NaN         NaN  \n",
       "2                 NaN         NaN  \n",
       "3                 NaN         NaN  \n",
       "4                 NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "\n",
    "REPO_ID = \"datasetmaster/resumes\"\n",
    "FILENAME = \"master_resumes.jsonl\"\n",
    "\n",
    "\n",
    "IT_resume_df = pd.read_json(\n",
    "    hf_hub_download(repo_id=REPO_ID, filename=FILENAME, repo_type=\"dataset\"),\n",
    "    lines = True\n",
    ")\n",
    "\n",
    "print(type(IT_resume_df))\n",
    "IT_resume_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3090f",
   "metadata": {},
   "source": [
    "Cấu hình ngưỡng của broadcast cực nhỏ để khi chạy join() thì auto là sort-merge join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cấu hình broadcast để thử nghiệm với dữ liệu nhỏ\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# cấu hình từ đầu\n",
    "spark_auto = SparkSession.builder \\\n",
    "    .appName(\"AutoBroadcastJoin\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"20971520\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# cấu hình trong lúc chạy\n",
    "spark_auto.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 32)  # 15MB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e805fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Thay thế Job Title thành các cột tương ứng\n",
    "IT_job_detail_df = IT_job_df.join(\n",
    "    IT_skill_df,\n",
    "    IT_job_df['Job Title']== IT_skill_df['Job Title'],\n",
    "    'inner'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61936613",
   "metadata": {},
   "source": [
    "Xử lý job - resume : explode + join theo key là skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode cột skill trong 2 bảng\n",
    "IT_job_exploded_df = IT_job_detail_df.withColumn(\"Skills\", F.explode(\"Skills\"))\n",
    "IT_resume_exploded_df = IT_resume_exploded_df.withColumn(\"Skills\", F.explode(\"Skills\"))\n",
    "\n",
    "# Join 2 bảng với cột đã có, tạo ra một bảng cực lớn\n",
    "IT_job_resume_df = IT_job_exploded_df.join(\n",
    "    IT_skill_exploded_df,\n",
    "    IT_job_exploded_df['Skills'] == IT_skill_exploded_df['Skills'],\n",
    "    'inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf25279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b02b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363754da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39704fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu df dạng Parquet vào HDFS\n",
    "# TODO: Cần thay đổi đường dẫn HDFS phù hợp với hệ thống \n",
    "try:\n",
    "    IT_job_detail_df.write.mode(\"overwrite\").parquet(\"hdfs://namenode_host:9000/user/your_user/mydata_parquet\")\n",
    "    print(\"✅ Lưu Parquet thành công vào HDFS\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Lỗi khi lưu Parquet: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c59315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9553871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a672774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ba55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bdbb199",
   "metadata": {},
   "source": [
    "**Xử lý _Multiple Joins Optimization_** \n",
    "\n",
    "Mục tiêu là giảm số lần shuffle và điều chỉnh thứ tự join để tối ưu\n",
    "\n",
    "Tối ưu thứ tự join (Thực hiện phép join giúp giảm kích thước data nhanh nhất trước):\n",
    "* Join các bảng nhỏ nhất trước: Join bảng thực tế (fact table) với các bảng chiều (dimension tables) nhỏ trước, đặc biệt là các bảng có thể được broadcast. Điều này giúp giảm kích thước của tập kết quả trung gian trước khi join với các bảng lớn hơn.\n",
    "\n",
    "* Sử dụng CBO (Cost-Based Optimizer): Spark có một bộ tối ưu hóa truy vấn (Query Optimizer) mạnh mẽ. Nó cố gắng tự động tìm ra thứ tự join tốt nhất dựa trên các số liệu thống kê (cardinality, kích thước bảng, v.v.). Trong đây thì cần thu thập thông kê các bảng lớn trước. ANALYZE TABLE ten_bang COMPUTE STATISTICS FOR ALL COLUMNS;\n",
    "\n",
    "Giảm shuffle:\n",
    "* Thường xuyên broadcast các bảng nhỏ\n",
    "* Dùng bucket join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6d4ff",
   "metadata": {},
   "source": [
    "Triển khai với 3 bảng job, company, skill:\n",
    "* join 2 bảng job và company trước rồi join bảng kết quả thu được với bảng skill\n",
    "* Có broadcast các bảng bé, partitioning bảng job với key job title trước để giảm số lần shuffle\n",
    "* Có thể sử dụng SQL Hint để tối ưu hóa hơn, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a70b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Thay thế company thành các tên cột tương ứng\n",
    "IT_job_company_df = IT_job_df.join(\n",
    "    broadcast(IT_company_df),\n",
    "    IT_job_df['Company']== IT_company_df['Company'],\n",
    "    'inner'\n",
    ")\n",
    "\n",
    "IT_job_company_skill_df = IT_job_company_df.join(\n",
    "    IT_skill_df,\n",
    "    IT_job_company_df['Job Title']== IT_skill_df['Job Title'],\n",
    "    'inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956024a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dùng CBO thử cho tác vụ này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313f740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968bf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e62ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e8f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c632e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
